{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f5320af-853f-4ccb-9b3c-7e2f0e136763",
   "metadata": {},
   "source": [
    "# Data Mining: Fundamentals\n",
    "## Michelangelo Leoni and Jacopo Omodei\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455ed4e4-26e9-4b3f-b8e7-62fba1520871",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "\n",
    "[Intro](#intro)\n",
    "\n",
    "[Data Understanding](#data_understanding)\n",
    "\n",
    "[Data Preparation](#data_preparation)\n",
    "\n",
    "\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c48c0f-3c8a-4d05-b201-1a8a0c29345c",
   "metadata": {},
   "source": [
    "# Introduction (Slides 0)\n",
    "\n",
    "<a id=\"intro\"></a>\n",
    "\n",
    "What is __data mining?__ It is the use off efficient techniques for the _analysis_ of _very large collections of data_ and the _extraction_ of useful and hidden knowledge. \n",
    "\n",
    "__Primary data__ is original data that has been collected for a specific purpose (not altered by humans), while __secondary data__ is data that has already been collected and made available for other purposes (can come from many sources). \n",
    "\n",
    "## CRISP-DM:\n",
    "__Cross-Industry Standard Process for Data Mining__. Reliable and repeatable data mining process in the field. \n",
    "- __Business understanding__\n",
    "    - Understand what the __client wants__ to accomplish (business goals)\n",
    "    - Assess the situation (resources, constraints, assumptions)\n",
    "    - Determine data mining goals (how will we achieve the client's goal?)\n",
    "    - Produce project plan\n",
    "- __Data understanding__\n",
    "    - Explore the data\n",
    "        - Key attributes and their relations\n",
    "        - Properties of sub-populations\n",
    "        - If needed transform and prepare the data\n",
    "    - Verify the quality of data (is it complete?)\n",
    "    - Find outliers\n",
    "    - Collect initial data (data loading, data integration from multiple sources)\n",
    "    - Describe data (surface properties)\n",
    "- __Data preparation__\n",
    "    - Select data (which is useful?)\n",
    "    - Clean data\n",
    "    - Construct data (derived attributes or trasformed values)\n",
    "    - Integrate data\n",
    "    - Format data (without changing its meaning)\n",
    "- __Modeling__\n",
    "    - Select the technique (based on the data mining objective)\n",
    "    - Test the model (seperate the data into training and validation to see how well the model fits the data)\n",
    "    - Build the model and then assess it based on your criteria\n",
    "- __Evaluation__\n",
    "    - Evaluate how well the model performed on the test data (to what degree it meets the business objectives)\n",
    "    -  Review the results, modifying if necessary\n",
    "- __Deployment__\n",
    "    - Plan deployment\n",
    "        - How do we want to present our results?\n",
    "        - What are our results (is it a report? A model? An algorithm?)\n",
    "    - Plan monitoring and maintenance\n",
    "    - Produce final report\n",
    "    - Review project\n",
    "\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4418de8-2349-4228-bcfb-69c0506ba8e2",
   "metadata": {},
   "source": [
    "<a id=\"data_understanding\"></a>\n",
    "# Data Understanding (slides 1)\n",
    "\n",
    "It's fundamental to have an overall understanding of your data. We need to gain insight on your data with respect to our project goals and to understand the data's fundamental properties. For example, what kind of attributes do we have, and how are they correlated? How is the quality of the data? How are missing values handled? Do we need to extract other attributes? etc.\n",
    "\n",
    "## Data\n",
    "What is data? A collection of data objects and their attributes. An __attribute__ (_variable, field, characteristic, dimention, feature_) is a property or charactetristic of an object (while an __object__ (_record, point, case, sample, entity, instance_)is defined as a collection of attributes)\n",
    "\n",
    "### Types of data: \n",
    "- __Record:__\n",
    "    - Data matrix (table)\n",
    "        - Objects have the same fixed set of attributes\n",
    "        - Objects are points in a fixed dimention multi-dim space\n",
    "    - Document data  <img align=\"right\" width=\"250\" src=\"figures/document_data.png\">\n",
    "        - Each term (word or phrase) is an attribute of the vector\n",
    "        - The value of each attribute is the number of times the corresponding term occurs in the document\n",
    "    - Transaction data (each record is a transaction that involves a set of items)\n",
    "- __Graph:__ (directionally connected nodes)\n",
    "  - Examples: World Wide Web, molecular structures, social networks\n",
    "- __Ordered:__\n",
    "    - Spatial-temporal data\n",
    "    - Sequential data\n",
    "    - Genetic sequence data  \n",
    "\n",
    "### Types of attributes:\n",
    "- __Nominal/categorical:__ attribute values in a finite domain, categories\n",
    "    - Ex: ID numbers, eye color, zip codes\n",
    "- __Binary:__ _nominal attribute_ with only two states (0 and 1)\n",
    "    - Symmetric binary: 0/1 equally important (ex: gender)\n",
    "    - Asymmetric binary: 1 is the presence of something (important) while 0 is the absence\n",
    "- __Ordinal:__ finite domain with meaningful ordering on the domain\n",
    "    - Ex: Rankings, grades, height\n",
    "- __Numeric:__ quantity (integer or real-valued)\n",
    "    - Interval-scaled: measured on a scale of equal-sized units, and the values have order. Example: calendar dates, temperature in C\n",
    "- __Ratio-scaled:__ values being an order of magnitude larger than the unit of measurement\n",
    "    - Ex: length, counts, elapsed time. (A game lasting 3 hours is _50% longer_ than a game lasting 2 hours)  \n",
    "\n",
    "### Data quality:\n",
    "Naturally, bad data can lead to incorrect conclusions and is to be avoided if possible. Some possible data quality issues can be:\n",
    "- __Syntatctic accuracy:__ entry not in the domain\n",
    "    - Ex: text in numerical attributes, typos\n",
    "- __Semantic accuracy:__ data is in the domain but not correct\n",
    "    - Ex: John Smith classified as female (though is male). Needs more information to be checked (you may not catch that J.S is a male, though you could catch a negative value in a defined-positive attribute)\n",
    "- __Completeness__\n",
    "- __Unbalanced data:__ data is biased to one type of record\n",
    "- __Timeliness:__ is the data up to date?\n",
    "- __Duplicate data:__ duplicates or almost duplicates (like merging from heterogeneous sources)\n",
    "    - Ex: one person with multiple email addresses\n",
    "\n",
    "### Data visualization:\n",
    "Different types of statistical tools and charts may be used to best convey the patterns in the data. For example, scatterplots, bar charts, or __histograms__. The number of bins in a histogram is a fundamental parameter that drastically can change the usefulness of the presented data. The number of bins according to __Sturges' rule__ is \\$k=\\left[\\log_2{(n)}+1\\right]\\$ where _n_ is the sample size. This rule is useful for normal distributions and moderately-sized datasets.\n",
    "\n",
    "You can then use this number of bins to set _k_ equally-sized bins in the interval, or to create _k_ equally populated (but differently-sized) bins in the interval. There are also different binning practices, but these are the most common (and the first one is the most widely-used).\n",
    "\n",
    "Data can be distributed in all sorts of ways, for example data can be __symmetric__, __bimodal__ (presenting two clear peaks), __positively skewed__ (with a long positive tail mean>mode), or __negatively skewed__ (long negative tail mean<mode)\n",
    "\n",
    "<img align=\"right\" width=\"110\" src=\"figures/box_whisker.png\">\n",
    "\n",
    "__Box plot:__ five-number summary of a distribution. \n",
    "The data is represented with a box whose edges are the first and third quartiles (25% and 75%, respectively). The middle of the box (marked with a line) is the second quartile (50%, median). The whiskers (two lines out from the box) extend to the 1st, 5th or 10th percentile (depends on the convention) and 99th, 95th, 90th percentile respectively. Any points beyond the whiskers are outliers. \n",
    "In general, the p%-quartile is the value of _x_ so that p% of the values are smaller \n",
    "\n",
    "What box plots lack is the distribution of the data (two datasets can have the same quartiles but different distributions). Histograms instead are perfect for showing these further patterns.\n",
    "\n",
    "__Scatter plots:__ can be useful to see clusters of points, outliers and correlations. They are limited by the fact that in higher dimensions they quickly become illeggible and sparse. However, to plot bivariate data (one attribute vs another) they can be quite useful. As shown in the figure, you can use scatterplot matrices to plot every attribute vs every other attribute in a dataset. \n",
    "\n",
    "<img align=\"center\" width=\"200\" src=\"figures/scatter_matrix.png\">\n",
    "\n",
    "\n",
    "__Radar plot:__ Coordinates are drawn in a star-like fashion, with each tip of the star being an attribute. Each pattern is a polygon within this space extending outwards for higher values of the attribute.\n",
    "\n",
    "<img align=\"center\" width=\"200\" src=\"figures/radarplot.png\">\n",
    "\n",
    "### Correlation:\n",
    "The sample __Pearson's correlation coefficient__ is a measure for a linear relationship between two numerical attributes X and Y and is defined as \\$r_{xy} = \\frac{\\sum_{i=1}^n(x_i-\\bar{x})(y_i-\\bar{y})}{(n-1)s_xs_y};\\$ \\$r_{xy}\\in[-1,1]\\$\n",
    "where \\$\\bar{x},\\bar{y}\\$ are the mean values of X and Y, and \\$s_x,s_y\\$ are the corresponding sample standard deviations.\n",
    "\n",
    "The larger the absolute value of the Pearson correlation coefficient, the stronger the linear relationship between the two attributes. For maximum correlation \\$|r_{xy}|=1\\$ and the values of X and Y line on a line. Positive (negative) correlation indicates a line with positive (negative) slope. \n",
    "\n",
    "\n",
    "### Outliers:\n",
    "Outliers can be very annoying or very interesting. They can be because of noise, and effectively harmful for the data (potentially look to exclude them) or they can be the very case of our study (the verification of a rare but desired event). Outliers can be detected by looking at their frequency (low histogram count), numerical attribute (outside the whiskers in the box plot), they can be outliers with respect to one or more attributes (seen in scatter plots), and can also be found through cluster analysis. \n",
    "\n",
    "Oftentimes it is still useful to exlude correct (not born from noise but from rare events) outliers in our analysis, noting the fact that we have done so.\n",
    "\n",
    "\n",
    "\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8452e13-e088-4fbc-af0f-7f8de3c063ba",
   "metadata": {},
   "source": [
    "<a id=\"data_preparation\"></a>\n",
    "# Data Preparation (slides 2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b7cbd5-00ef-43c6-a590-af6fd30f12c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
